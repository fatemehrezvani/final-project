{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_(2) (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plooRJ_1EqX0",
        "outputId": "283da8e3-50f1-4274-bb2e-0bed0c5d62ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "import numpy as np \n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "def dataset_preparation(data):\n",
        "\n",
        "\t# basic cleanup\n",
        "\tcorpus = data.lower().split(\"\\t\")\n",
        "\n",
        "\t# tokenization\t\n",
        "\ttokenizer.fit_on_texts(corpus)\n",
        "\ttotal_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "\t# create input sequences using list of tokens\n",
        "\tinput_sequences = []\n",
        "\tfor line in corpus:\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\t\tfor i in range(1, len(token_list)):\n",
        "\t\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\t# pad sequences \n",
        "\tmax_sequence_len = max([len(x) for x in input_sequences])\n",
        "\tinput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "\t# create predictors and label\n",
        "\tpredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\tlabel = ku.to_categorical(label, num_classes=total_words)\n",
        "\n",
        "\treturn predictors, label, max_sequence_len, total_words\n",
        "\n",
        "def create_model(predictors, label, max_sequence_len, total_words):\n",
        "\t\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
        "\tmodel.add(LSTM(150, return_sequences = True))\n",
        "\t# model.add(Dropout(0.2))\n",
        "\tmodel.add(LSTM(100))\n",
        "\tmodel.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\tearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "\tmodel.fit(predictors, label, epochs=5, verbose=1, callbacks=[earlystop])\n",
        "\tprint (model.summary())\n",
        "\treturn model \n",
        "\n",
        "def generate_text(seed_text, next_words, max_sequence_len):\n",
        "\tfor _ in range(next_words):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\t\t\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\tseed_text += \" \" + output_word\n",
        "\treturn seed_text\n",
        "\n",
        "\n",
        "\n",
        "data = open('data.txt').read()\n",
        "\n",
        "predictors, label, max_sequence_len, total_words = dataset_preparation(data)\n",
        "model = create_model(predictors, label, max_sequence_len, total_words)\n",
        "print (generate_text(\"job have already been\", 1, max_sequence_len))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "23655/23655 [==============================] - 3929s 166ms/step - loss: 6.7223 - acc: 0.0266\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1478, 10)          20040     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 1478, 150)         96600     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               100400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2004)              202404    \n",
            "=================================================================\n",
            "Total params: 419,444\n",
            "Trainable params: 419,444\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "job have already been to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W0r2838tErSn",
        "colab": {}
      },
      "source": [
        "# باید فایل data.txt را کنار ان قرارداده و ران بگیرید تا نتیجه را مشاهده کنید"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VsqNDfdwtR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}